Traceback (most recent call last):
  File "/Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages/jupyter_cache/executors/utils.py", line 58, in single_nb_execution
    executenb(
  File "/Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages/nbclient/client.py", line 1305, in execute
    return NotebookClient(nb=nb, resources=resources, km=km, **kwargs).execute()
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/d/Library/Python/3.11/lib/python/site-packages/jupyter_core/utils/__init__.py", line 166, in wrapped
    return loop.run_until_complete(inner)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/asyncio/base_events.py", line 653, in run_until_complete
    return future.result()
           ^^^^^^^^^^^^^^^
  File "/Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages/nbclient/client.py", line 705, in async_execute
    await self.async_execute_cell(
  File "/Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages/nbclient/client.py", line 1058, in async_execute_cell
    await self._check_raise_for_error(cell, cell_index, exec_reply)
  File "/Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages/nbclient/client.py", line 914, in _check_raise_for_error
    raise CellExecutionError.from_cell_and_msg(cell, exec_reply_content)
nbclient.exceptions.CellExecutionError: An error occurred while executing the following cell:
------------------
import requests
from bs4 import BeautifulSoup
from tabulate import tabulate

def scrape_influencers():
    # URL of the influencers page on SEMrush
    url = "https://www.semrush.com/website/influencers/"

    # Send a GET request to the URL and retrieve the content
    response = requests.get(url)
    content = response.text

    # Create a BeautifulSoup object to parse the HTML content
    soup = BeautifulSoup(content, "html.parser")

    # Find the table containing the influencers
    table = soup.find("table", class_="data-table")

    # Extract the influencer data from the table
    influencers = []
    rows = table.find_all("tr")[1:]  # Exclude the header row
    for row in rows:
        columns = row.find_all("td")
        if len(columns) >= 4:
            position = columns[0].text.strip()
            account = columns[1].text.strip()
            audience = columns[2].text.strip()
            statistics = columns[3].text.strip()
            influencers.append([position, account, audience, statistics])

    return influencers

# Scrape the influencers data
influencers_table = scrape_influencers()

# Print the influencers table
print(tabulate(influencers_table, headers=["Position", "Account", "Audience", "Statistics"]))

------------------


[0;31m---------------------------------------------------------------------------[0m
[0;31mAttributeError[0m                            Traceback (most recent call last)
Cell [0;32mIn[1], line 34[0m
[1;32m     31[0m     [38;5;28;01mreturn[39;00m influencers
[1;32m     33[0m [38;5;66;03m# Scrape the influencers data[39;00m
[0;32m---> 34[0m influencers_table [38;5;241m=[39m [43mscrape_influencers[49m[43m([49m[43m)[49m
[1;32m     36[0m [38;5;66;03m# Print the influencers table[39;00m
[1;32m     37[0m [38;5;28mprint[39m(tabulate(influencers_table, headers[38;5;241m=[39m[[38;5;124m"[39m[38;5;124mPosition[39m[38;5;124m"[39m, [38;5;124m"[39m[38;5;124mAccount[39m[38;5;124m"[39m, [38;5;124m"[39m[38;5;124mAudience[39m[38;5;124m"[39m, [38;5;124m"[39m[38;5;124mStatistics[39m[38;5;124m"[39m]))

Cell [0;32mIn[1], line 21[0m, in [0;36mscrape_influencers[0;34m()[0m
[1;32m     19[0m [38;5;66;03m# Extract the influencer data from the table[39;00m
[1;32m     20[0m influencers [38;5;241m=[39m []
[0;32m---> 21[0m rows [38;5;241m=[39m [43mtable[49m[38;5;241;43m.[39;49m[43mfind_all[49m([38;5;124m"[39m[38;5;124mtr[39m[38;5;124m"[39m)[[38;5;241m1[39m:]  [38;5;66;03m# Exclude the header row[39;00m
[1;32m     22[0m [38;5;28;01mfor[39;00m row [38;5;129;01min[39;00m rows:
[1;32m     23[0m     columns [38;5;241m=[39m row[38;5;241m.[39mfind_all([38;5;124m"[39m[38;5;124mtd[39m[38;5;124m"[39m)

[0;31mAttributeError[0m: 'NoneType' object has no attribute 'find_all'

