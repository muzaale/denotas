{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 08/01/2023\n",
    "\n",
    "### 825. [undergrads](https://jhutrc.github.io/fenagas/content/dramatispersonae/undergraduates.html)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "tags": [
     "hide-input"
    ]
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number     Name                          \n",
      "1          Stephanie Perez               \n",
      "2          Harold Rhodes                 \n",
      "3          Danielle Villarreal           \n",
      "4          Laura Griffin                 \n",
      "5          Matthew Jimenez               \n",
      "6          Michael Smith                 \n",
      "7          Michael Huffman               \n",
      "8          Courtney Lane                 \n",
      "9          Holly Beltran                 \n",
      "10         Craig Boyle                   \n"
     ]
    }
   ],
   "source": [
    "from faker import Faker\n",
    "\n",
    "def generate_random_names(num_names):\n",
    "    fake = Faker()\n",
    "    names = [[fake.first_name(), fake.last_name()] for _ in range(num_names)]\n",
    "    return names\n",
    "\n",
    "def create_table(names):\n",
    "    header = [\"Number\", \"Name\"]\n",
    "    table = []\n",
    "    table.append(header)\n",
    "    for idx, name in enumerate(names, start=1):\n",
    "        full_name = \" \".join(name)\n",
    "        row = [idx, full_name]\n",
    "        table.append(row)\n",
    "\n",
    "    # Printing the table\n",
    "    for row in table:\n",
    "        print(f\"{row[0]:<10} {row[1]:<30}\")\n",
    "\n",
    "# Generate 10 random names and call the function\n",
    "random_names = generate_random_names(10)\n",
    "create_table(random_names)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 826. graçias &#128591;\n",
    "\n",
    "+ beta version of the fenagas webapp is up & running\n",
    "+ andrew & fawaz will be first to test it\n",
    "+ consider rolling it out to faculty in department \n",
    "+ philosophe, elliot, betsy, and with residents\n",
    "\n",
    "### 827. fenagas\n",
    "\n",
    "+ let ai say about `fena` \"annuŋŋamya mu makubo ago butukirivu\"\n",
    "+ ai can't produce such nuance on its own\n",
    "+ but, guided, it can\n",
    "\n",
    "### 828. music\n",
    "\n",
    "+ take me to church on apple music\n",
    "+ my fave playlist\n",
    "+ *savor it!*\n",
    "\n",
    "### 829. boards\n",
    "\n",
    "+ my scores are expired\n",
    "+ i need to retake them\n",
    "+ will be fun with ai \n",
    "+ consider a timeline\n",
    "+ and with fenagas,llc?\n",
    "+ just might have bandwidth\n",
    "+ but its the synthesis of the two\n",
    "+ that will be the most fun\n",
    "\n",
    "### 830. breakthru\n",
    "\n",
    "Act I: Hypothesis - Navigating the Realm of Ideas and Concepts\n",
    "\n",
    "In Act I, we embark on a journey of exploration, where ideas take center stage. We delve into the realm of hypotheses and concepts, laying the foundation for our scientific inquiry. From conceiving research questions to formulating testable propositions, Act I serves as the starting point of our intellectual pursuit. Through manuscripts, code, and Git, we learn to articulate and organize our ideas effectively, setting the stage for robust investigations and insightful discoveries.\n",
    "\n",
    "Act II: Data - Unveiling the Power of Information\n",
    "\n",
    "Act II unfolds as we dive into the realm of data, where raw information becomes the fuel for knowledge. Through the lenses of Python, AI, R, and Stata, we explore data collection, processing, and analysis. Act II empowers us to harness the potential of data and unleash its power in extracting meaningful insights. By mastering the tools to handle vast datasets and uncover patterns, Act II equips us to bridge the gap between theoretical hypotheses and empirical evidence.\n",
    "\n",
    "Act III: Estimates - Seeking Truth through Inference\n",
    "\n",
    "In Act III, we venture into the world of estimates, where statistical methods guide us in drawing meaningful conclusions. Nonparametric, semiparametric, parametric, and simulation techniques become our allies in the quest for truth. Act III enables us to infer population characteristics from sample data, making informed decisions and drawing reliable generalizations. Understanding the nuances of estimation empowers us to extract valuable information from limited observations, transforming data into actionable knowledge.\n",
    "\n",
    "Act IV: Variance - Grappling with Uncertainty\n",
    "\n",
    "Act IV brings us face to face with variance, where uncertainty and variability loom large. In the pursuit of truth, we encounter truth, rigor, error, sloppiness, and the unsettling specter of fraud. Act IV teaches us to navigate the intricacies of uncertainty, recognize the sources of variation, and identify potential pitfalls. By embracing variance, we fortify our methodologies, enhance the rigor of our analyses, and guard against errors and biases that may distort our findings.\n",
    "\n",
    "Act V: Explanation - Illuminating the \"Why\" behind the \"What\"\n",
    "\n",
    "Act V marks the pinnacle of our journey, where we seek to unravel the mysteries behind observed phenomena. Oneway, Twoway, Multivariable, Hierarchical, Clinical, and Public perspectives converge in a quest for understanding. Act V unfolds the rich tapestry of explanations, exploring causal relationships, uncovering hidden connections, and interpreting complex findings. By delving into the intricacies of explanation, Act V empowers us to communicate our discoveries, inspire new research avenues, and drive positive change in our scientific pursuits.\n",
    "\n",
    "Epilogue: Embracing the Journey of Knowledge\n",
    "\n",
    "In the Epilogue, we reflect on our expedition through Fenagas, celebrating the richness of knowledge and the evolution of our understanding. Open Science, Self-publishing, Published works, Grants, Proposals, and the interconnected world of Git & Spoke symbolize the culmination of our endeavors. Epilogue serves as a reminder of the ever-growing landscape of learning and the profound impact our contributions can have. Embracing the spirit of curiosity, we step forward, armed with newfound wisdom, to navigate the boundless seas of knowledge and ignite the flame of discovery in ourselves and others.\n",
    "\n",
    "### 831. fenagas\n",
    "\n",
    "+ each paper, manuscript, or project should have its own set of repos\n",
    "+ these will necessarily include a mixture of private and public repos\n",
    "+ private repos will be used for collaboration\n",
    "+ the public repos will be used for publication\n",
    "+ fenagas is a private company and recruitor\n",
    "+ so it will have its own set of repos as well\n",
    "+ but the science and research will have its own repos\n",
    "\n",
    "### 832. jerktaco\n",
    "\n",
    "+ oxtail\n",
    "+ jerk chicken\n",
    "+ chilli-fried whole jerk snapper. is that a thing? quick google says yes.\n",
    "\n",
    "### 833. eddie\n",
    "\n",
    "Kadi and Mark…    \n",
    "+ The square root of the number of employees you employ will do most of the work… \n",
    "+ 5 classical composers created 95% of the classical music that’s played \n",
    "+ and yet if you look at their music, only 5% of their music is what’s played 95% of the time”…. \n",
    "+ Debate"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 08/02/2023\n",
    "\n",
    "### 834. fena\n",
    "\n",
    "+ fawaz initally mistook persian and urdu for arabic\n",
    "+ and read them out but said they made no sense\n",
    "+ then recognized the \"middle one\" as arabic\n",
    "+ with the meaning that is intended\n",
    "+ but probably no idiomatic"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " No.   Phrase                     Language         English Translation       \n",
      " 1     Eno yaffe ffena.           Luganda          Our and by us.            \n",
      " 2     Nuestro y por nosotros     Spanish          Ours and by us            \n",
      " 3     Le nôtre et par nous       French           Ours and by us            \n",
      " 4     Unser und von uns          German           Ours and by us            \n",
      " 5     Nostro e da noi            Italian          Ours and by us            \n",
      " 6     Nosso e por nós            Portuguese       Ours and by us            \n",
      " 7     Ons en door ons            Dutch            Ours and by us            \n",
      " 8     Наш и нами                 Russian          Ours and by us            \n",
      " 9     हमारा और हमसे              Hindi            Ours and by us            \n",
      " 10    हमारा और हमसे              Nepali           Ours and by us            \n",
      " 11    نا و توسط ما               Persian          Ours and by us            \n",
      " 12    私たちのものであり、私たちによって          Japanese         Ours and by us            \n",
      " 13    لنا وبواسطتنا              Arabic           Ours and by us            \n",
      " 14    שלנו ועל ידינו             Hebrew           Ours and by us            \n",
      " 15    Yetu na kwa sisi           Swahili          Ours and by us            \n",
      " 16    Yetu futhi ngathi sisi     Zulu             Ours and like us          \n",
      " 17    Tiwa ni aṣẹ ati nipa wa    Yoruba           Ours and through us       \n",
      " 18    A ka na anyi               Igbo             Ours and by us            \n",
      " 19    우리의 것이며, 우리에 의해            Korean           Ours and by us            \n",
      " 20    Meidän ja meidän toimesta  Finnish          Ours and by us            \n",
      " 21    ኦህድዎና በእኛ                  Amharic          Ours and by us            \n",
      " 22    Hinqabu fi hinqabu jechuun  Oromo            Ours and through us       \n",
      " 23    ምንም ነገርና እኛ በእኛ            Tigrinya         Nothing and by us         \n",
      " 24    हमारा और हमसे              Marathi          Ours and by us            \n",
      " 25    અમારા અને અમારા દ્વારા     Gujarati         Ours and by us            \n",
      " 26    ما و توسط ما               Urdu             Ours and by us            \n"
     ]
    }
   ],
   "source": [
    "data = [\n",
    "    (\"Eno yaffe ffena.\", \"Luganda\", \"Our and by us.\"),\n",
    "    (\"Nuestro y por nosotros\", \"Spanish\", \"Ours and by us\"),\n",
    "    (\"Le nôtre et par nous\", \"French\", \"Ours and by us\"),\n",
    "    (\"Unser und von uns\", \"German\", \"Ours and by us\"),\n",
    "    (\"Nostro e da noi\", \"Italian\", \"Ours and by us\"),\n",
    "    (\"Nosso e por nós\", \"Portuguese\", \"Ours and by us\"),\n",
    "    (\"Ons en door ons\", \"Dutch\", \"Ours and by us\"),\n",
    "    (\"Наш и нами\", \"Russian\", \"Ours and by us\"),\n",
    "    (\"हमारा और हमसे\", \"Hindi\", \"Ours and by us\"),\n",
    "    (\"हमारा और हमसे\", \"Nepali\", \"Ours and by us\"),\n",
    "    (\"نا و توسط ما\", \"Persian\", \"Ours and by us\"),\n",
    "    (\"私たちのものであり、私たちによって\", \"Japanese\", \"Ours and by us\"),\n",
    "    (\"لنا وبواسطتنا\", \"Arabic\", \"Ours and by us\"),\n",
    "    (\"שלנו ועל ידינו\", \"Hebrew\", \"Ours and by us\"),\n",
    "    (\"Yetu na kwa sisi\", \"Swahili\", \"Ours and by us\"),\n",
    "    (\"Yetu futhi ngathi sisi\", \"Zulu\", \"Ours and like us\"),\n",
    "    (\"Tiwa ni aṣẹ ati nipa wa\", \"Yoruba\", \"Ours and through us\"),\n",
    "    (\"A ka na anyi\", \"Igbo\", \"Ours and by us\"),\n",
    "    (\"우리의 것이며, 우리에 의해\", \"Korean\", \"Ours and by us\"),\n",
    "    (\"Meidän ja meidän toimesta\", \"Finnish\", \"Ours and by us\"),\n",
    "    (\"ኦህድዎና በእኛ\", \"Amharic\", \"Ours and by us\"),\n",
    "    (\"Hinqabu fi hinqabu jechuun\", \"Oromo\", \"Ours and through us\"),\n",
    "    (\"ምንም ነገርና እኛ በእኛ\", \"Tigrinya\", \"Nothing and by us\"),\n",
    "    (\"हमारा और हमसे\", \"Marathi\", \"Ours and by us\"),\n",
    "    (\"અમારા અને અમારા દ્વારા\", \"Gujarati\", \"Ours and by us\"),\n",
    "    (\"ما و توسط ما\", \"Urdu\", \"Ours and by us\"),\n",
    "]\n",
    "\n",
    "def print_table(data):\n",
    "    print(\" {:<4}  {:<25}  {:<15}  {:<25} \".format(\"No.\", \"Phrase\", \"Language\", \"English Translation\"))\n",
    "    print(\"\" + \"-\" * 6 + \"\" + \"-\" * 32 + \"\" + \"-\" * 17 + \"\" + \"-\" * 27 + \"\")\n",
    "    for idx, (phrase, language, translation) in enumerate(data, 1):\n",
    "        print(\" {:<4}  {:<25}  {:<15}  {:<25} \".format(idx, phrase, language, translation))\n",
    "\n",
    "print_table(data)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.2"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
